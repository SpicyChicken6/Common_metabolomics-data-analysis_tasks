{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This file contains definitions of functions to be implemented for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data reading\n",
    "\n",
    "def get_file_path(sub_dir1,sub_dir2,filename):\n",
    "    tool_directory=Path.cwd()\n",
    "    #project_directory=os.path.dirname(tool_directory)\n",
    "    data_directory=os.path.join(tool_directory,sub_dir1,sub_dir2,filename)\n",
    "    return data_directory\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Read the data from the data folder and return a pandas dataframe\n",
    "\n",
    "    Args:\n",
    "        filename (str, optional): Name of the file to read. Defaults to \"human_cachexia.csv\".\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe containing the data\n",
    "    \"\"\"\n",
    "    input_data=pd.read_csv(filename)\n",
    "    print(\"data read successfully, the shape of the dataframe is: \", input_data.shape)\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read successfully, the shape of the dataframe is:  (77, 65)\n"
     ]
    }
   ],
   "source": [
    "###test function\n",
    "\n",
    "data_file=\"/Users/yuzhijian/Documents/学习资料/UMICH/UM2023/Winter_2023/Bioinf 576/tool_github/resources/test_dataset/human_cachexia.csv\"\n",
    "\n",
    "data_file=read_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>1,6-Anhydro-beta-D-glucose</th>\n",
       "      <th>1-Methylnicotinamide</th>\n",
       "      <th>2-Aminobutyrate</th>\n",
       "      <th>2-Hydroxyisobutyrate</th>\n",
       "      <th>2-Oxoglutarate</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>3-Hydroxybutyrate</th>\n",
       "      <th>3-Hydroxyisovalerate</th>\n",
       "      <th>...</th>\n",
       "      <th>Tryptophan</th>\n",
       "      <th>Tyrosine</th>\n",
       "      <th>Uracil</th>\n",
       "      <th>Valine</th>\n",
       "      <th>Xylose</th>\n",
       "      <th>cis-Aconitate</th>\n",
       "      <th>myo-Inositol</th>\n",
       "      <th>trans-Aconitate</th>\n",
       "      <th>pi-Methylhistidine</th>\n",
       "      <th>tau-Methylhistidine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIF_178</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>40.85</td>\n",
       "      <td>65.37</td>\n",
       "      <td>18.73</td>\n",
       "      <td>26.05</td>\n",
       "      <td>71.52</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>56.83</td>\n",
       "      <td>10.07</td>\n",
       "      <td>...</td>\n",
       "      <td>259.82</td>\n",
       "      <td>290.03</td>\n",
       "      <td>111.05</td>\n",
       "      <td>86.49</td>\n",
       "      <td>72.24</td>\n",
       "      <td>237.46</td>\n",
       "      <td>135.64</td>\n",
       "      <td>51.94</td>\n",
       "      <td>157.59</td>\n",
       "      <td>160.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIF_087</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>62.18</td>\n",
       "      <td>340.36</td>\n",
       "      <td>24.29</td>\n",
       "      <td>41.68</td>\n",
       "      <td>67.36</td>\n",
       "      <td>116.75</td>\n",
       "      <td>43.82</td>\n",
       "      <td>79.84</td>\n",
       "      <td>...</td>\n",
       "      <td>83.10</td>\n",
       "      <td>167.34</td>\n",
       "      <td>46.99</td>\n",
       "      <td>109.95</td>\n",
       "      <td>192.48</td>\n",
       "      <td>333.62</td>\n",
       "      <td>376.15</td>\n",
       "      <td>217.02</td>\n",
       "      <td>307.97</td>\n",
       "      <td>130.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIF_090</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>270.43</td>\n",
       "      <td>64.72</td>\n",
       "      <td>12.18</td>\n",
       "      <td>65.37</td>\n",
       "      <td>23.81</td>\n",
       "      <td>14.30</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.34</td>\n",
       "      <td>...</td>\n",
       "      <td>82.27</td>\n",
       "      <td>60.34</td>\n",
       "      <td>31.50</td>\n",
       "      <td>59.15</td>\n",
       "      <td>2164.62</td>\n",
       "      <td>330.30</td>\n",
       "      <td>86.49</td>\n",
       "      <td>58.56</td>\n",
       "      <td>145.47</td>\n",
       "      <td>83.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NETL_005_V1</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>154.47</td>\n",
       "      <td>52.98</td>\n",
       "      <td>172.43</td>\n",
       "      <td>74.44</td>\n",
       "      <td>1199.91</td>\n",
       "      <td>555.57</td>\n",
       "      <td>175.91</td>\n",
       "      <td>25.03</td>\n",
       "      <td>...</td>\n",
       "      <td>235.10</td>\n",
       "      <td>323.76</td>\n",
       "      <td>30.57</td>\n",
       "      <td>102.51</td>\n",
       "      <td>125.21</td>\n",
       "      <td>1863.11</td>\n",
       "      <td>247.15</td>\n",
       "      <td>75.94</td>\n",
       "      <td>249.64</td>\n",
       "      <td>254.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIF_115</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>22.20</td>\n",
       "      <td>73.70</td>\n",
       "      <td>15.64</td>\n",
       "      <td>83.93</td>\n",
       "      <td>33.12</td>\n",
       "      <td>29.67</td>\n",
       "      <td>76.71</td>\n",
       "      <td>69.41</td>\n",
       "      <td>...</td>\n",
       "      <td>103.54</td>\n",
       "      <td>142.59</td>\n",
       "      <td>44.26</td>\n",
       "      <td>160.77</td>\n",
       "      <td>186.79</td>\n",
       "      <td>101.49</td>\n",
       "      <td>749.95</td>\n",
       "      <td>98.49</td>\n",
       "      <td>84.77</td>\n",
       "      <td>79.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>NETCR_019_V2</td>\n",
       "      <td>control</td>\n",
       "      <td>35.16</td>\n",
       "      <td>52.46</td>\n",
       "      <td>13.87</td>\n",
       "      <td>44.26</td>\n",
       "      <td>99.48</td>\n",
       "      <td>208.51</td>\n",
       "      <td>11.25</td>\n",
       "      <td>6.49</td>\n",
       "      <td>...</td>\n",
       "      <td>46.06</td>\n",
       "      <td>45.15</td>\n",
       "      <td>62.18</td>\n",
       "      <td>33.45</td>\n",
       "      <td>62.80</td>\n",
       "      <td>103.54</td>\n",
       "      <td>78.26</td>\n",
       "      <td>18.17</td>\n",
       "      <td>871.31</td>\n",
       "      <td>84.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NETL_012_V1</td>\n",
       "      <td>control</td>\n",
       "      <td>16.95</td>\n",
       "      <td>15.80</td>\n",
       "      <td>10.49</td>\n",
       "      <td>22.42</td>\n",
       "      <td>62.80</td>\n",
       "      <td>10.91</td>\n",
       "      <td>6.96</td>\n",
       "      <td>3.46</td>\n",
       "      <td>...</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.33</td>\n",
       "      <td>31.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>14.30</td>\n",
       "      <td>36.23</td>\n",
       "      <td>11.59</td>\n",
       "      <td>12.30</td>\n",
       "      <td>53.52</td>\n",
       "      <td>44.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NETL_012_V2</td>\n",
       "      <td>control</td>\n",
       "      <td>9.39</td>\n",
       "      <td>14.01</td>\n",
       "      <td>5.16</td>\n",
       "      <td>23.57</td>\n",
       "      <td>46.99</td>\n",
       "      <td>13.33</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>14.88</td>\n",
       "      <td>15.18</td>\n",
       "      <td>39.65</td>\n",
       "      <td>13.74</td>\n",
       "      <td>21.76</td>\n",
       "      <td>40.85</td>\n",
       "      <td>30.88</td>\n",
       "      <td>8.50</td>\n",
       "      <td>90.02</td>\n",
       "      <td>28.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NETL_003_V1</td>\n",
       "      <td>control</td>\n",
       "      <td>37.71</td>\n",
       "      <td>18.17</td>\n",
       "      <td>26.05</td>\n",
       "      <td>15.03</td>\n",
       "      <td>23.34</td>\n",
       "      <td>33.45</td>\n",
       "      <td>6.05</td>\n",
       "      <td>5.26</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>29.96</td>\n",
       "      <td>13.46</td>\n",
       "      <td>14.59</td>\n",
       "      <td>36.97</td>\n",
       "      <td>90.92</td>\n",
       "      <td>17.64</td>\n",
       "      <td>12.43</td>\n",
       "      <td>897.85</td>\n",
       "      <td>90.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NETL_003_V2</td>\n",
       "      <td>control</td>\n",
       "      <td>38.47</td>\n",
       "      <td>12.55</td>\n",
       "      <td>15.03</td>\n",
       "      <td>12.55</td>\n",
       "      <td>22.20</td>\n",
       "      <td>21.33</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.42</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>23.57</td>\n",
       "      <td>9.58</td>\n",
       "      <td>10.59</td>\n",
       "      <td>19.89</td>\n",
       "      <td>58.56</td>\n",
       "      <td>24.29</td>\n",
       "      <td>13.07</td>\n",
       "      <td>83.93</td>\n",
       "      <td>27.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient ID Muscle loss  1,6-Anhydro-beta-D-glucose  \\\n",
       "0        PIF_178    cachexic                       40.85   \n",
       "1        PIF_087    cachexic                       62.18   \n",
       "2        PIF_090    cachexic                      270.43   \n",
       "3    NETL_005_V1    cachexic                      154.47   \n",
       "4        PIF_115    cachexic                       22.20   \n",
       "..           ...         ...                         ...   \n",
       "72  NETCR_019_V2     control                       35.16   \n",
       "73   NETL_012_V1     control                       16.95   \n",
       "74   NETL_012_V2     control                        9.39   \n",
       "75   NETL_003_V1     control                       37.71   \n",
       "76   NETL_003_V2     control                       38.47   \n",
       "\n",
       "    1-Methylnicotinamide  2-Aminobutyrate  2-Hydroxyisobutyrate  \\\n",
       "0                  65.37            18.73                 26.05   \n",
       "1                 340.36            24.29                 41.68   \n",
       "2                  64.72            12.18                 65.37   \n",
       "3                  52.98           172.43                 74.44   \n",
       "4                  73.70            15.64                 83.93   \n",
       "..                   ...              ...                   ...   \n",
       "72                 52.46            13.87                 44.26   \n",
       "73                 15.80            10.49                 22.42   \n",
       "74                 14.01             5.16                 23.57   \n",
       "75                 18.17            26.05                 15.03   \n",
       "76                 12.55            15.03                 12.55   \n",
       "\n",
       "    2-Oxoglutarate  3-Aminoisobutyrate  3-Hydroxybutyrate  \\\n",
       "0            71.52             1480.30              56.83   \n",
       "1            67.36              116.75              43.82   \n",
       "2            23.81               14.30               5.64   \n",
       "3          1199.91              555.57             175.91   \n",
       "4            33.12               29.67              76.71   \n",
       "..             ...                 ...                ...   \n",
       "72           99.48              208.51              11.25   \n",
       "73           62.80               10.91               6.96   \n",
       "74           46.99               13.33               3.35   \n",
       "75           23.34               33.45               6.05   \n",
       "76           22.20               21.33               5.99   \n",
       "\n",
       "    3-Hydroxyisovalerate  ...  Tryptophan  Tyrosine  Uracil  Valine   Xylose  \\\n",
       "0                  10.07  ...      259.82    290.03  111.05   86.49    72.24   \n",
       "1                  79.84  ...       83.10    167.34   46.99  109.95   192.48   \n",
       "2                  23.34  ...       82.27     60.34   31.50   59.15  2164.62   \n",
       "3                  25.03  ...      235.10    323.76   30.57  102.51   125.21   \n",
       "4                  69.41  ...      103.54    142.59   44.26  160.77   186.79   \n",
       "..                   ...  ...         ...       ...     ...     ...      ...   \n",
       "72                  6.49  ...       46.06     45.15   62.18   33.45    62.80   \n",
       "73                  3.46  ...       21.33     21.33   31.19   13.20    14.30   \n",
       "74                  2.69  ...       14.88     15.18   39.65   13.74    21.76   \n",
       "75                  5.26  ...       17.46     29.96   13.46   14.59    36.97   \n",
       "76                  3.42  ...       27.66     23.57    9.58   10.59    19.89   \n",
       "\n",
       "    cis-Aconitate  myo-Inositol  trans-Aconitate  pi-Methylhistidine  \\\n",
       "0          237.46        135.64            51.94              157.59   \n",
       "1          333.62        376.15           217.02              307.97   \n",
       "2          330.30         86.49            58.56              145.47   \n",
       "3         1863.11        247.15            75.94              249.64   \n",
       "4          101.49        749.95            98.49               84.77   \n",
       "..            ...           ...              ...                 ...   \n",
       "72         103.54         78.26            18.17              871.31   \n",
       "73          36.23         11.59            12.30               53.52   \n",
       "74          40.85         30.88             8.50               90.02   \n",
       "75          90.92         17.64            12.43              897.85   \n",
       "76          58.56         24.29            13.07               83.93   \n",
       "\n",
       "    tau-Methylhistidine  \n",
       "0                160.77  \n",
       "1                130.32  \n",
       "2                 83.93  \n",
       "3                254.68  \n",
       "4                 79.84  \n",
       "..                  ...  \n",
       "72                84.77  \n",
       "73                44.70  \n",
       "74                28.22  \n",
       "75                90.02  \n",
       "76                27.39  \n",
       "\n",
       "[77 rows x 65 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##normalization methods\n",
    "\n",
    "def normalize_by_sum(input_data):\n",
    "    '''\n",
    "    Normalize the data by dividing each column by the sum of the row\n",
    "\n",
    "    Args:\n",
    "        input_data (pandas.DataFrame): Dataframe containing the data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Normalized dataframe\n",
    "    '''\n",
    "    data_to_process=input_data.iloc[:,2:]\n",
    "    normalized_data=data_to_process.div(data_to_process.sum(axis=0), axis=1)\n",
    "    normed_data=input_data.copy()\n",
    "    normed_data.iloc[:,2:]=normalized_data\n",
    "    \n",
    "    return normed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_norm=normalize_by_sum(data_file).iloc[:,2:].sum(axis=0)\n",
    "after_norm[0:].sum(axis=0)==len(after_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_by_median(input_data):\n",
    "    '''\n",
    "    Normalize the data by dividing each column by the median of the row\n",
    "\n",
    "    Args:\n",
    "        input_data (pandas.DataFrame): Dataframe containing the data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Normalized dataframe\n",
    "    '''\n",
    "\n",
    "    data_to_process=input_data.iloc[:,2:]\n",
    "    normalized_data=data_to_process.div(data_to_process.median(axis=0), axis=1)\n",
    "    normed_data=input_data.copy()\n",
    "    normed_data.iloc[:,2:]=normalized_data\n",
    "\n",
    "    return normed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_by_reference_sample_PQN(input_data):\n",
    "    '''\n",
    "    Normalize the data by dividing each column by the PQN of the reference sample. \n",
    "    PQN has been shown to be effective at normalizing data from different platforms and technologies, \n",
    "    and can reduce batch effects and other systematic variations in data. However, \n",
    "    PQN assumes that most genes or proteins are not differentially expressed, which may not be true in all cases. \n",
    "    Additionally, PQN may not be appropriate for all types of data, \n",
    "    and other normalization methods may be more appropriate \n",
    "    depending on the specific research question and experimental design.\n",
    "\n",
    "    Args:\n",
    "        input_data (pandas.DataFrame): Dataframe containing the data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Normalized dataframe\n",
    "\n",
    "    '''\n",
    "    data_to_process=input_data.iloc[:,2:]\n",
    "    sample_medians = data_to_process.median(axis=0)\n",
    "    data_norm = data_to_process.div(sample_medians, axis=1)\n",
    "    metabolite_means = np.exp(np.log(data_norm).mean(axis=1))\n",
    "    data_norm = data_norm.div(metabolite_means, axis=0)\n",
    "    col_medians = data_norm.median(axis=0)\n",
    "    data_norm = data_norm.div(col_medians, axis=1)\n",
    "    normed_data=input_data.copy()\n",
    "    normed_data.iloc[:,2:]=data_norm\n",
    "\n",
    "    return normed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation_log(input_data):\n",
    "    '''\n",
    "    Transform the data by taking the log10 of each value\n",
    "\n",
    "    Args:\n",
    "        input_data (pandas.DataFrame): Dataframe containing the data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Transformed dataframe\n",
    "    '''\n",
    "\n",
    "    data_to_process=input_data.iloc[:,2:]\n",
    "    data_log10 = data_to_process.apply(np.log10)\n",
    "    transformed_data=input_data.copy()\n",
    "    transformed_data.iloc[:,2:]=data_log10\n",
    "    \n",
    "    return transformed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaling_mean_centered(input_data):\n",
    "    '''\n",
    "    Scale the data by subtracting the mean of each column from each value in the column\n",
    "\n",
    "    Args:\n",
    "        input_data (pandas.DataFrame): Dataframe containing the data\n",
    "\n",
    "    Returns:    \n",
    "        pandas.DataFrame: Scaled dataframe\n",
    "    '''\n",
    "\n",
    "    data_scaled = input_data.subtract(input_data.mean(axis=0), axis=1)\n",
    "    scaled_data=input_data.copy()\n",
    "    scaled_data.iloc[:,2:]=data_scaled\n",
    "\n",
    "    return scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_analysis(input_data, number_of_components=2):\n",
    "    '''\n",
    "    Perform PCA analysis on the data\n",
    "    \n",
    "    Args:\n",
    "        input_data (pandas.DataFrame): Dataframe containing the data\n",
    "        number_of_components (int, optional): Number of principal components to return. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe containing the principal components\n",
    "    '''\n",
    "\n",
    "    # Load data into a Pandas DataFrame\n",
    "\n",
    "    # Initialize PCA object with desired number of components\n",
    "    pca = PCA(n_components=number_of_components)\n",
    "\n",
    "    # Fit the PCA model to the data\n",
    "    pca.fit(input_data)\n",
    "\n",
    "    # Transform the data to the new coordinate system defined by the principal components\n",
    "    data_pca = pca.transform(input_data)\n",
    "\n",
    "    # Create a new DataFrame with the principal components\n",
    "    df_pca = pd.DataFrame(data=data_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "    return df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_plot(df_pca):\n",
    "    '''\n",
    "    Plot the PCA analysis results\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.pyplot: Plot of the PCA analysis results\n",
    "    '''\n",
    "\n",
    "    # Plot the principal components\n",
    "    plt.scatter(df_pca['PC1'], df_pca['PC2'])\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.show()\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to be implemented\n",
    "def MA_plot():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##interface for user to select the normalization method and data transformation method\n",
    "def user_interface():\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c3ba5c41ad9dd74bd7117685cd73f7cb15f5937a6b2e8e86fa38521c5647524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
